{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3aea8fb1e50b4052956d52a78073e810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0401afa737e414ca9d1261811f291ed",
              "IPY_MODEL_750ab18405954aa2a508a83ac6563221",
              "IPY_MODEL_7867ea7c6e324c1983f5abe818885b4c"
            ],
            "layout": "IPY_MODEL_15611dfa2ed74cb78cce274894a0d351"
          }
        },
        "b0401afa737e414ca9d1261811f291ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc0e9ea8ca848fa93d27c689098b2fc",
            "placeholder": "​",
            "style": "IPY_MODEL_570cddf114ce4f88815e293484ecd6d1",
            "value": "Map: 100%"
          }
        },
        "750ab18405954aa2a508a83ac6563221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f538d39f966747d6a281a7d82457c364",
            "max": 4076,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b7552e37444f7091cc1a74dd38a48b",
            "value": 4076
          }
        },
        "7867ea7c6e324c1983f5abe818885b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1588c6ebfd844f07be32df30818a6e7d",
            "placeholder": "​",
            "style": "IPY_MODEL_7dc0cfe281e44e1d8dbdfa3bb677c581",
            "value": " 4076/4076 [00:02&lt;00:00, 1786.65 examples/s]"
          }
        },
        "15611dfa2ed74cb78cce274894a0d351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc0e9ea8ca848fa93d27c689098b2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570cddf114ce4f88815e293484ecd6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f538d39f966747d6a281a7d82457c364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b7552e37444f7091cc1a74dd38a48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1588c6ebfd844f07be32df30818a6e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc0cfe281e44e1d8dbdfa3bb677c581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZioTTxZmvl-",
        "outputId": "482ac3ab-fab0-4eb8-db27-69b92b85fffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load JSONL from your repo\n",
        "url = \"https://raw.githubusercontent.com/affan002/DimABSA-SemEval-task03/refs/heads/main/train/eng_laptop_train_alltasks.jsonl?token=GHSAT0AAAAAADFHNCHZDQLRRFHHZTTVLGCM2GT2CHA\"\n",
        "df = pd.read_json(url, lines=True)\n",
        "\n",
        "rows = []\n",
        "for _, row in df.iterrows():\n",
        "    text = row[\"Text\"]\n",
        "    for quad in row[\"Quadruplet\"]:\n",
        "        aspect = quad[\"Aspect\"]\n",
        "        opinion = quad[\"Opinion\"]\n",
        "        va = quad[\"VA\"]\n",
        "        valence, arousal = map(float, va.split(\"#\"))\n",
        "\n",
        "        rows.append({\n",
        "            \"Text\": text,\n",
        "            \"Aspect\": aspect,\n",
        "            \"Opinion\": opinion,\n",
        "            \"Valence\": valence,\n",
        "            \"Arousal\": arousal\n",
        "        })\n",
        "\n",
        "raw_datasets = Dataset.from_pandas(pd.DataFrame(rows))"
      ],
      "metadata": {
        "id": "S9Sg1DHinrMY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
        "\n",
        "# --- Load pretrained tokenizer and add [NULL] token ---\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "special_tokens_dict = {'additional_special_tokens': ['[NULL]']}\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# --- Define label mapping (added NULL label) ---\n",
        "label_list = [\"O\", \"B-ASP\", \"I-ASP\", \"B-OPI\", \"I-OPI\"]\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n",
        "print(\"Label mapping:\", label2id, id2label)\n",
        "\n",
        "# --- Function to create BIO labels ---\n",
        "def create_bio_labels(text, quadruplets):\n",
        "    words = text.split()\n",
        "    labels = [\"O\"] * len(words)\n",
        "\n",
        "    for quad in quadruplets:\n",
        "        aspect = quad[\"Aspect\"]\n",
        "        opinion = quad[\"Opinion\"]\n",
        "\n",
        "        # Aspect span\n",
        "        if aspect != \"NULL\":\n",
        "            aspect_tokens = aspect.split()\n",
        "            for i, token in enumerate(words):\n",
        "                if token.lower() == aspect_tokens[0].lower():  # simple first token match\n",
        "                    labels[i] = \"B-ASP\"\n",
        "                    if len(aspect_tokens) > 1:\n",
        "                        for j in range(1, len(aspect_tokens)):\n",
        "                            if i + j < len(words):\n",
        "                                labels[i + j] = \"I-ASP\"\n",
        "\n",
        "        # Opinion span\n",
        "        if opinion != \"NULL\":\n",
        "            opinion_tokens = opinion.split()\n",
        "            for i, token in enumerate(words):\n",
        "                if token.lower() == opinion_tokens[0].lower():\n",
        "                    labels[i] = \"B-OPI\"\n",
        "                    if len(opinion_tokens) > 1:\n",
        "                        for j in range(1, len(opinion_tokens)):\n",
        "                            if i + j < len(words):\n",
        "                                labels[i + j] = \"I-OPI\"\n",
        "\n",
        "    # Prepend [NULL] token (always O)\n",
        "    words = [\"[NULL]\"] + words\n",
        "    labels = [\"O\"] + labels\n",
        "\n",
        "    return words, [label2id[l] for l in labels]\n",
        "\n",
        "# --- Convert dataset to word-level BIO format ---\n",
        "rows = []\n",
        "for _, row in df.iterrows():\n",
        "    words, labels = create_bio_labels(row[\"Text\"], row[\"Quadruplet\"])\n",
        "    rows.append({\"tokens\": words, \"labels\": labels})\n",
        "\n",
        "bio_dataset = Dataset.from_pandas(pd.DataFrame(rows))\n",
        "\n",
        "print(bio_dataset[0])\n",
        "\n",
        "# --- Tokenize & align labels ---\n",
        "def tokenize_and_align_labels(batch):\n",
        "    tokenized = tokenizer(batch[\"tokens\"], is_split_into_words=True, truncation=True, padding=False)\n",
        "    aligned_labels = []\n",
        "\n",
        "    for i, labels in enumerate(batch[\"labels\"]):\n",
        "        word_ids = tokenized.word_ids(batch_index=i)\n",
        "        new_labels = []\n",
        "        prev_word = None\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                new_labels.append(-100)  # ignore special tokens\n",
        "            elif word_id != prev_word:\n",
        "                new_labels.append(labels[word_id])\n",
        "            else:\n",
        "                new_labels.append(-100)  # only label first subword\n",
        "            prev_word = word_id\n",
        "        aligned_labels.append(new_labels)\n",
        "\n",
        "    tokenized[\"labels\"] = aligned_labels\n",
        "    return tokenized\n",
        "\n",
        "tokenized_datasets = bio_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# --- Data collator ---\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer) # this collator will be used in dataloader\n",
        "\n",
        "print(tokenized_datasets.column_names)\n",
        "print(tokenized_datasets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "3aea8fb1e50b4052956d52a78073e810",
            "b0401afa737e414ca9d1261811f291ed",
            "750ab18405954aa2a508a83ac6563221",
            "7867ea7c6e324c1983f5abe818885b4c",
            "15611dfa2ed74cb78cce274894a0d351",
            "7cc0e9ea8ca848fa93d27c689098b2fc",
            "570cddf114ce4f88815e293484ecd6d1",
            "f538d39f966747d6a281a7d82457c364",
            "97b7552e37444f7091cc1a74dd38a48b",
            "1588c6ebfd844f07be32df30818a6e7d",
            "7dc0cfe281e44e1d8dbdfa3bb677c581"
          ]
        },
        "id": "zkuGjxx6p6Yx",
        "outputId": "0f6ef03f-af89-4deb-ad51-982f21fd66f9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {'O': 0, 'B-ASP': 1, 'I-ASP': 2, 'B-OPI': 3, 'I-OPI': 4} {0: 'O', 1: 'B-ASP', 2: 'I-ASP', 3: 'B-OPI', 4: 'I-OPI'}\n",
            "{'tokens': ['[NULL]', 'this', 'unit', 'is', '`', '`', 'pretty', '`', '`', 'and', 'stylish', ',', 'so', 'my', 'high', 'school', 'daughter', 'was', 'attracted', 'to', 'it', 'for', 'that', 'reason', '.'], 'labels': [0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4076 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aea8fb1e50b4052956d52a78073e810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataCollatorForTokenClassification(tokenizer=BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[NULL]']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t30522: AddedToken(\"[NULL]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')\n",
            "['tokens', 'labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
            "{'tokens': ['[NULL]', 'this', 'unit', 'is', '`', '`', 'pretty', '`', '`', 'and', 'stylish', ',', 'so', 'my', 'high', 'school', 'daughter', 'was', 'attracted', 'to', 'it', 'for', 'that', 'reason', '.'], 'labels': [-100, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], 'input_ids': [101, 30522, 2023, 3131, 2003, 1036, 1036, 3492, 1036, 1036, 1998, 2358, 8516, 4509, 1010, 2061, 2026, 2152, 2082, 2684, 2001, 6296, 2000, 2009, 2005, 2008, 3114, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"tokens\"])\n",
        "\n",
        "# Convert dataset to PyTorch tensors\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Check final columns\n",
        "print(tokenized_datasets.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQXMl_ahtLXh",
        "outputId": "3c823010-b1cc-4b5d-8f3a-6f37893566e0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train/validation/test\n",
        "# First: train + temp (where temp will be split further into val + test)\n",
        "dataset_splits = tokenized_datasets.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_dataset = dataset_splits[\"train\"]\n",
        "temp_dataset = dataset_splits[\"test\"]\n",
        "\n",
        "# Now split temp into validation and test (50/50 → 10% val, 10% test overall)\n",
        "temp_splits = temp_dataset.train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "eval_dataset = temp_splits[\"train\"]   # validation set\n",
        "test_dataset = temp_splits[\"test\"]    # final test set\n",
        "\n",
        "# Make DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=8, collate_fn=data_collator\n",
        ")\n"
      ],
      "metadata": {
        "id": "dRcSHwZfqXa1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader: #inspecting the batch\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZRKPrjq8op",
        "outputId": "5e6998e5-cf4e-441d-9f04-7bed5d2f3d9d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 45]),\n",
              " 'token_type_ids': torch.Size([8, 45]),\n",
              " 'attention_mask': torch.Size([8, 45]),\n",
              " 'labels': torch.Size([8, 45])}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModelForTokenClassification\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(label_list),   # e.g., 5: O, B-ASP, I-ASP, B-OPI, I-OPI\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(checkpoint, config=config)\n",
        "\n",
        "# Resize embeddings if you added special tokens like [NULL]\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXm2HS2NsYzq",
        "outputId": "64e2504d-2e01-46dc-f906-b679b6103934"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30523, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the batch through the model\n",
        "outputs = model(**batch)\n",
        "\n",
        "# Cross-entropy loss for token classification\n",
        "print(\"Loss:\", outputs.loss)\n",
        "\n",
        "# Logits shape: (batch_size, seq_len, num_labels)\n",
        "print(\"Logits shape:\", outputs.logits.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxasSjQsus_6",
        "outputId": "83a4e437-cb5e-41e6-dcfd-b99494e9a5a8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(1.5172, grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([8, 45, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Define optimizer that updates the model's parameters\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "# ⚠️ The only thing you might tune later:\n",
        "# Learning rate (lr) → try 5e-5, 3e-5, or 1e-5 to see which gives better results.\n",
        "# Weight decay → if overfitting, you can add e.g. weight_decay=0.01."
      ],
      "metadata": {
        "id": "6xpm5m5JwryW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "# Train for more epochs since dataset is small\n",
        "num_epochs = 5   # you can try 5, 8, or even 10\n",
        "\n",
        "# Total number of training steps\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "\n",
        "# Warmup = 10% of training steps\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",                # linear decay schedule\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,   # gradual warmup\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "print(f\"Total steps: {num_training_steps}, Warmup steps: {num_warmup_steps}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BavHu8ze0J5",
        "outputId": "3719c4c7-50f7-43ab-ab64-21859c41d97a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total steps: 2040, Warmup steps: 204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Step 1: Choose device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Step 2: Move the model to the chosen device\n",
        "model.to(device)\n",
        "device\n"
      ],
      "metadata": {
        "id": "YMEGsP06fGPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKgqWdathSj_",
        "outputId": "30d30337-ab41-4b9e-e633-19997cb2bc72"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=29a439e30dfa96b5ed4575bb7c98889b0fa4cac7409464db9e581ccdd0f570d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 5  # you can adjust\n",
        "best_f1 = 0.0   # track best F1 for checkpointing\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ------------------- TRAINING -------------------\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    train_progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\")\n",
        "\n",
        "    for batch in train_progress_bar:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f\"\\nEpoch {epoch+1}: Avg Train Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ------------------- VALIDATION -------------------\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    val_progress_bar = tqdm(eval_dataloader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in val_progress_bar:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            for pred_seq, label_seq, mask_seq in zip(predictions, batch[\"labels\"], batch[\"attention_mask\"]):\n",
        "                pred_labels = []\n",
        "                true_labels = []\n",
        "                for p, l, m in zip(pred_seq, label_seq, mask_seq):\n",
        "                    if l.item() != -100 and m.item() == 1:\n",
        "                        pred_labels.append(id2label[p.item()])\n",
        "                        true_labels.append(id2label[l.item()])\n",
        "                all_preds.append(pred_labels)\n",
        "                all_labels.append(true_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    print(f\"Validation — F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "    # ------------------- CHECKPOINT -------------------\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        save_path = \"./best_model\"\n",
        "        model.save_pretrained(save_path)\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "        print(f\"New best model saved at F1 = {f1:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "oOSV4wwCfux6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}